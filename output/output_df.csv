File,Location,Lines,Code,Element name,Element type
main.py,\main.py,9.0,LOGGER = logging.getLogger(__name__),main.py,Code
main.py,\main.py,18.0,"    LOGGER.exception(""Uncaught exception: {0}"".format(str(value)))",exception_handler,Function
main.py,\main.py,43.0,LOGGER.info(,main.py,Code
initialise_run.py,\engine\initialise_run.py,35.0,LOGGER = logging.getLogger(__name__),initialise_run.py,Code
initialise_run.py,\engine\initialise_run.py,64.0,"        LOGGER.info(f""{round(i / len(list_filepaths) * 100)}% of {settings.glob_location} templates processed"")",batch_runs,Function
initialise_run.py,\engine\initialise_run.py,73.0,"                    LOGGER.info(f""Ignored {filename} as this is a defaulted case"")",batch_runs,Function
initialise_run.py,\engine\initialise_run.py,241.0,"                    print(f""{filename} added to misspelled files"")",batch_runs,Function
initialise_run.py,\engine\initialise_run.py,244.0,"                    print(f'ignored ""{filename}"" as this is not approved or v13 or a more recent version is available')",batch_runs,Function
initialise_run.py,\engine\initialise_run.py,248.0,"            print(f'""{filename}"" failed with ""{e}""')",batch_runs,Function
initialise_run.py,\engine\initialise_run.py,277.0,"    pd_output_project_info.to_csv(settings.output_dir / ""all_pd_project_info.csv"")",batch_runs,Function
initialise_run.py,\engine\initialise_run.py,278.0,"    ead_lgd_output_project_info.to_csv(settings.output_dir / ""all_ead_lgd_project_info.csv"")",batch_runs,Function
initialise_run.py,\engine\initialise_run.py,279.0,"    files_not_run.to_csv(settings.output_dir / ""all_not_run.csv"")",batch_runs,Function
initialise_run.py,\engine\initialise_run.py,295.0,"        pd.concat(deal_totals_output, axis=0).to_csv(settings.output_dir / ""deal_totals_output.csv"")",batch_runs,Function
initialise_run.py,\engine\initialise_run.py,296.0,"        pd.concat(tranche_totals_output, axis=0).to_csv(settings.output_dir / ""tranche_totals_output.csv"")",batch_runs,Function
initialise_run.py,\engine\initialise_run.py,297.0,"    misspelled_filenames.to_csv(settings.output_dir / ""misspelled_filenames.csv"")",batch_runs,Function
initialise_run.py,\engine\initialise_run.py,343.0,"    LOGGER.info(f""start {file_names_project[0]}"")",run_model,Function
initialise_run.py,\engine\initialise_run.py,348.0,"    LOGGER.info(""%s parameter file will be used"", settings.parameter_file_name)",run_model,Function
initialise_run.py,\engine\initialise_run.py,365.0,"            LOGGER.info(f""read {file_names_project[0]} from cache"")",run_model,Function
initialise_run.py,\engine\initialise_run.py,372.0,            pickle.dump(,run_model,Function
initialise_run.py,\engine\initialise_run.py,379.0,"            LOGGER.info(f""read {file_names_project[0]} from excel file"")",run_model,Function
initialise_run.py,\engine\initialise_run.py,387.0,"        LOGGER.info(f""read {file_names_project[0]} from cache"")",run_model,Function
initialise_run.py,\engine\initialise_run.py,395.0,        pickle.dump(,run_model,Function
initialise_run.py,\engine\initialise_run.py,404.0,"    pickle.dump(inputs_tuple, open(settings.saved_pickle_dir, ""wb""))",run_model,Function
initialise_run.py,\engine\initialise_run.py,446.0,"    LOGGER.info(""Deal data has been read in"")",run_model,Function
initialise_run.py,\engine\initialise_run.py,507.0,"    LOGGER.info(""Qualitative factors have been read in"")",run_model,Function
initialise_run.py,\engine\initialise_run.py,547.0,"    LOGGER.info(""Parameters have been read in"")",run_model,Function
initialise_run.py,\engine\initialise_run.py,631.0,"    LOGGER.info(""Simulation finalised and outputs saved"")",run_model,Function
logger.py,\engine\logger.py,34.0,        # Add the handlers to the LOGGER,setup_logger,Function
project_finance_it.py,\engine\project_finance_it.py,97.0,"    print(""start default parameter calculation"")",project_finance_it,Function
project_finance_it.py,\engine\project_finance_it.py,98.0,"    print(""Calculate PD"")",project_finance_it,Function
project_finance_it.py,\engine\project_finance_it.py,144.0,"    print(""start calculate EAD"")",project_finance_it,Function
project_finance_it.py,\engine\project_finance_it.py,149.0,"    print(""start LGD"")",project_finance_it,Function
cash_waterfall.py,\engine\cash_waterfall\cash_waterfall.py,22.0,LOGGER = logging.getLogger(__name__),cash_waterfall.py,Code
cash_waterfall.py,\engine\cash_waterfall\cash_waterfall.py,82.0,"        LOGGER.info(""Iterative calculation, year %d, "" + df_deal_info[""deal_name""][0], year)",iterative_equity_cash_covenants_default,Function
cash_waterfall.py,\engine\cash_waterfall\cash_waterfall.py,111.0,"        LOGGER.info(""Performing cash and equity calculation"")",iterative_equity_cash_covenants_default,Function
cash_waterfall.py,\engine\cash_waterfall\cash_waterfall.py,118.0,"        LOGGER.info(""Performing cash updates calculation"")",iterative_equity_cash_covenants_default,Function
cash_waterfall.py,\engine\cash_waterfall\cash_waterfall.py,175.0,"        LOGGER.info(""Performing revolving injection calculation"")",iterative_equity_cash_covenants_default,Function
cash_waterfall.py,\engine\cash_waterfall\cash_waterfall.py,191.0,"        LOGGER.info(""Performing debt servicing check"")",iterative_equity_cash_covenants_default,Function
cash_waterfall.py,\engine\cash_waterfall\cash_waterfall.py,273.0,"        LOGGER.info(""Performing cash sweep"")",iterative_equity_cash_covenants_default,Function
cash_waterfall.py,\engine\cash_waterfall\cash_waterfall.py,417.0,"        LOGGER.info(""Performing covenants check"")",iterative_equity_cash_covenants_default,Function
cash_waterfall.py,\engine\cash_waterfall\cash_waterfall.py,423.0,"        LOGGER.info(""Performing dividends payment calculation"")",iterative_equity_cash_covenants_default,Function
cash_waterfall.py,\engine\cash_waterfall\cash_waterfall.py,427.0,"        LOGGER.info(""Performing final cash & equity calculation"")",iterative_equity_cash_covenants_default,Function
cash_waterfall.py,\engine\cash_waterfall\cash_waterfall.py,437.0,"    LOGGER.info(""Default assessment complete for "" + df_deal_info[""deal_name""][0])",iterative_equity_cash_covenants_default,Function
cash_waterfall_functions.py,\engine\cash_waterfall\cash_waterfall_functions.py,7.0,LOGGER = logging.getLogger(__name__),cash_waterfall_functions.py,Code
iterative_setup.py,\engine\cash_waterfall\iterative_setup.py,9.0,LOGGER = logging.getLogger(__name__),iterative_setup.py,Code
read_deal_template.py,\engine\data_layer\read_deal_template.py,10.0,LOGGER = logging.getLogger(__name__),read_deal_template.py,Code
read_deal_template.py,\engine\data_layer\read_deal_template.py,61.0,"        LOGGER.info(""Periodicity not valid: "" + periodicity)",period_conversion,Function
read_deal_template.py,\engine\data_layer\read_deal_template.py,197.0,"        LOGGER.info(""Columns lost during groupby"")",year_aggregation,Function
read_deal_template.py,\engine\data_layer\read_deal_template.py,222.0,        LOGGER.info(,read_sheet,Function
read_deal_template.py,\engine\data_layer\read_deal_template.py,238.0,"        LOGGER.info(""Columns which should be empty in general information contain "" ""input in file "" + name)",reshape_sheets,Function
read_deal_template.py,\engine\data_layer\read_deal_template.py,243.0,"        LOGGER.info(""Columns which should be empty before development starts "" ""contain input in file "" + name)",reshape_sheets,Function
read_deal_template.py,\engine\data_layer\read_deal_template.py,266.0,"        LOGGER.info(""Columns which should be empty in general information contain "" ""input in file "" + name)",reshape_sheets,Function
read_deal_template.py,\engine\data_layer\read_deal_template.py,272.0,"        LOGGER.info(""Columns which should be empty before revenue starts contain "" ""input in file "" + name)",reshape_sheets,Function
read_deal_template.py,\engine\data_layer\read_deal_template.py,708.0,"        LOGGER.info(""Periodicity not valid: "" + revenue_periodicity)",date_boundaries,Function
read_deal_template.py,\engine\data_layer\read_deal_template.py,2163.0,"        LOGGER.debug(f""Adjusted snapshot date to December {deal_general_info.sim_start_year.values[0]} for deal""",adjust_snapshot_based_on_maturity,Function
read_parameters.py,\engine\data_layer\read_parameters.py,6.0,LOGGER = logging.getLogger(__name__),read_parameters.py,Code
read_parameters.py,\engine\data_layer\read_parameters.py,21.0,"        LOGGER.info(""Parameters file contains non-identical duplicate entries"")",param_table_setup,Function
read_parameters.py,\engine\data_layer\read_parameters.py,314.0,        LOGGER.info(,param_template_join_up_volatility,Function
read_parameters.py,\engine\data_layer\read_parameters.py,328.0,        LOGGER.info(,param_template_join_up_volatility,Function
read_parameters.py,\engine\data_layer\read_parameters.py,336.0,        LOGGER.info(,param_template_join_up_volatility,Function
read_parameters.py,\engine\data_layer\read_parameters.py,345.0,        LOGGER.info(,param_template_join_up_volatility,Function
read_qual_input.py,\engine\data_layer\read_qual_input.py,8.0,LOGGER = logging.getLogger(__name__),read_qual_input.py,Code
read_qual_input.py,\engine\data_layer\read_qual_input.py,51.0,"        df_qual_input_full.to_pickle(full_path[:-5] + "".p"")",read_qual_input,Function
read_qual_input.py,\engine\data_layer\read_qual_input.py,116.0,"        df_scoping_full.to_pickle(full_path[:-5] + "".p"")",read_scoping_input,Function
template_code_join_up.py,\engine\data_layer\template_code_join_up.py,7.0,LOGGER = logging.getLogger(__name__),template_code_join_up.py,Code
template_code_join_up.py,\engine\data_layer\template_code_join_up.py,191.0,"            LOGGER.info(f""Cash flow currency {currency} should not be different than bp currency {bp_currency}"")",new_template_code_join_up,Function
default_parameters_functions.py,\engine\default_parameters\default_parameters_functions.py,9.0,LOGGER = logging.getLogger(__name__),default_parameters_functions.py,Code
default_parameters_functions.py,\engine\default_parameters\default_parameters_functions.py,64.0,"        LOGGER.info(""No defaults take place"")",default_flags,Function
miscellaneous.py,\engine\utils\miscellaneous.py,9.0,LOGGER = logging.getLogger(__name__),miscellaneous.py,Code
miscellaneous.py,\engine\utils\miscellaneous.py,42.0,"        LOGGER.info(""Year value compared to index value"")",year_index_check,Function
post_engine_scope_qualitative_score.py,\engine\utils\post_engine_scope_qualitative_score.py,8.0,LOGGER = logging.getLogger(__name__),post_engine_scope_qualitative_score.py,Code
post_engine_scope_qualitative_score.py,\engine\utils\post_engine_scope_qualitative_score.py,27.0,"            pickle.dump(data, open(path[:-5] + sheet + "".p"", ""wb""))",read_in_excel,Function
post_engine_scope_qualitative_score.py,\engine\utils\post_engine_scope_qualitative_score.py,32.0,"        pickle.dump(data, open(path[:-5] + sheet + "".p"", ""wb""))",read_in_excel,Function
post_engine_scope_qualitative_score.py,\engine\utils\post_engine_scope_qualitative_score.py,531.0,"            output_df.to_csv(settings.output_dir / ""templates_found_compared_to_reference.csv"", index=False)",check_files_processed_against_previous_run,Function
post_engine_scope_qualitative_score.py,\engine\utils\post_engine_scope_qualitative_score.py,674.0,    LOGGER.warning(,create_master_pd_output_file,Function
post_engine_scope_qualitative_score.py,\engine\utils\post_engine_scope_qualitative_score.py,734.0,"        df_output.to_csv(settings.output_dir / ""master_PD_output.csv"", index=False)",create_master_pd_output_file,Function
post_engine_scope_qualitative_score.py,\engine\utils\post_engine_scope_qualitative_score.py,736.0,"    LOGGER.info(""successfully completed"")",create_master_pd_output_file,Function
lgd_discriminatory_power_tests_excel_input.py,\scripts\analysis_scripts\lgd_discriminatory_power_tests_excel_input.py,92.0,    print(pd_discrim_power_df),run_discriminatory_power_tests,Function
lgd_discriminatory_power_tests_excel_input.py,\scripts\analysis_scripts\lgd_discriminatory_power_tests_excel_input.py,93.0,"    print(""\n"")",run_discriminatory_power_tests,Function
lgd_discriminatory_power_tests_excel_input.py,\scripts\analysis_scripts\lgd_discriminatory_power_tests_excel_input.py,109.0,    # print(lgd_discrim_power_df),run_discriminatory_power_tests,Function
lgd_discriminatory_power_tests_excel_input.py,\scripts\analysis_scripts\lgd_discriminatory_power_tests_excel_input.py,119.0,"    print(""\n ================= Model Development Discriminatory Power ================="")",lgd_discriminatory_power_tests_excel_input.py,Code
lgd_discriminatory_power_tests_excel_input.py,\scripts\analysis_scripts\lgd_discriminatory_power_tests_excel_input.py,122.0,"    print(""\n ================= Current Portfolio Discriminatory Power ================="")",lgd_discriminatory_power_tests_excel_input.py,Code
pd_discriminatory_power_abt.py,\scripts\analysis_scripts\pd_discriminatory_power_abt.py,66.0,"                print(f""For reporting date {rep_date} found {missing_values.sum()} NaN values for {pd_col}. """,generate_auc_results_at_reporting,Function
pd_discriminatory_power_abt.py,\scripts\analysis_scripts\pd_discriminatory_power_abt.py,79.0,"        print(f""For reporting date {rep_date} there are no defaults after 12 months. Filled with Zeros."")",generate_auc_results_at_reporting,Function
pd_discriminatory_power_abt.py,\scripts\analysis_scripts\pd_discriminatory_power_abt.py,95.0,"        print(f""Running Discriminatory Power for reporting date {reporting_date}"")",pd_discriminatory_power_abt.py,Code
pd_discriminatory_power_abt.py,\scripts\analysis_scripts\pd_discriminatory_power_abt.py,118.0,"    print(""\nAUC Results:"")",pd_discriminatory_power_abt.py,Code
pd_discriminatory_power_abt.py,\scripts\analysis_scripts\pd_discriminatory_power_abt.py,119.0,    print(auc_results_df),pd_discriminatory_power_abt.py,Code
pd_discriminatory_power_abt.py,\scripts\analysis_scripts\pd_discriminatory_power_abt.py,120.0,"    print(""\nGini Coefficient Results:"")",pd_discriminatory_power_abt.py,Code
pd_discriminatory_power_abt.py,\scripts\analysis_scripts\pd_discriminatory_power_abt.py,121.0,    print(gini_df),pd_discriminatory_power_abt.py,Code
pd_discriminatory_power_abt.py,\scripts\analysis_scripts\pd_discriminatory_power_abt.py,122.0,"    print(""\nC-Stat Results:"")",pd_discriminatory_power_abt.py,Code
pd_discriminatory_power_abt.py,\scripts\analysis_scripts\pd_discriminatory_power_abt.py,123.0,    print(c_stat_df),pd_discriminatory_power_abt.py,Code
pd_discriminatory_power_tests_excel_input.py,\scripts\analysis_scripts\pd_discriminatory_power_tests_excel_input.py,57.0,"            print(f""PD - Gini for {col}: {gini_coefficient.round(3)}, c-stat = {((gini_coefficient + 1) / 2).round(4)}"")",calculated_pd_gini,Function
pd_discriminatory_power_tests_excel_input.py,\scripts\analysis_scripts\pd_discriminatory_power_tests_excel_input.py,58.0,"            print(f""Number records: {len(pd_pred[filter])}, Number defaults: {sum(pd_actual[filter])}"")",calculated_pd_gini,Function
pd_discriminatory_power_tests_excel_input.py,\scripts\analysis_scripts\pd_discriminatory_power_tests_excel_input.py,64.0,    print(,calculated_pd_gini,Function
pd_discriminatory_power_tests_excel_input.py,\scripts\analysis_scripts\pd_discriminatory_power_tests_excel_input.py,67.0,"    print(f""Number records: {len(pd_pred[filter])}, Number defaults: {sum(pd_actual[filter])}"")",calculated_pd_gini,Function
pd_discriminatory_power_tests_excel_input.py,\scripts\analysis_scripts\pd_discriminatory_power_tests_excel_input.py,68.0,    print(),calculated_pd_gini,Function
pd_discriminatory_power_tests_excel_input.py,\scripts\analysis_scripts\pd_discriminatory_power_tests_excel_input.py,156.0,"    print(f""LCR - Gini: {lcr.round(3)}, c-stat = {((lcr + 1) / 2).round(3)}"")",pd_discriminatory_power_tests_excel_input.py,Code
pd_discriminatory_power_tests_smaller_input.py,\scripts\analysis_scripts\pd_discriminatory_power_tests_smaller_input.py,88.0,    print(pd_discrim_power_df),run_discriminatory_power_tests,Function
pd_discriminatory_power_tests_smaller_input.py,\scripts\analysis_scripts\pd_discriminatory_power_tests_smaller_input.py,89.0,"    print(""\n"")",run_discriminatory_power_tests,Function
pd_discriminatory_power_tests_smaller_input.py,\scripts\analysis_scripts\pd_discriminatory_power_tests_smaller_input.py,99.0,"    print(""\n ================= Model Development Discriminatory Power ================="")",pd_discriminatory_power_tests_smaller_input.py,Code
pd_discriminatory_power_tests_smaller_input.py,\scripts\analysis_scripts\pd_discriminatory_power_tests_smaller_input.py,105.0,"    print(""\n ================= Current Portfolio Discriminatory Power ================="")",pd_discriminatory_power_tests_smaller_input.py,Code
qual_module_cstat.py,\scripts\analysis_scripts\qual_module_cstat.py,51.0,"            print(f""{col} has {sum(~filter)} missing values"")",calculated_pd_gini,Function
qual_module_cstat.py,\scripts\analysis_scripts\qual_module_cstat.py,53.0,"            print(f""PD - Gini for {col}: {gini_coefficient.round(3)}, c-stat = {((gini_coefficient + 1) / 2).round(4)}"")",calculated_pd_gini,Function
qual_module_cstat.py,\scripts\analysis_scripts\qual_module_cstat.py,54.0,"            print(f""Number records: {len(pd_pred[filter])}, Number defaults: {sum(pd_actual[filter])}"")",calculated_pd_gini,Function
qual_module_cstat.py,\scripts\analysis_scripts\qual_module_cstat.py,63.0,        print(,calculated_pd_gini,Function
qual_module_cstat.py,\scripts\analysis_scripts\qual_module_cstat.py,67.0,"        print(f""Number records: {len(score_pred[filter])}, Number defaults: {sum(pd_actual[filter])}"")",calculated_pd_gini,Function
qual_module_cstat.py,\scripts\analysis_scripts\qual_module_cstat.py,80.0,    print(,calculated_pd_gini,Function
qual_module_cstat.py,\scripts\analysis_scripts\qual_module_cstat.py,134.0,    print(model.summary()),qual_module_cstat.py,Code
qual_module_cstat.py,\scripts\analysis_scripts\qual_module_cstat.py,136.0,    print(sum(y)),qual_module_cstat.py,Code
aggregate_templates_for_qa.py,\scripts\engine_scripts\aggregate_templates_for_qa.py,46.0,LOGGER = logging.getLogger(__name__),aggregate_templates_for_qa.py,Code
aggregate_templates_for_qa.py,\scripts\engine_scripts\aggregate_templates_for_qa.py,50.0,"    LOGGER.exception(""Uncaught exception: {0}"".format(str(value)))",exception_handler,Function
aggregate_templates_for_qa.py,\scripts\engine_scripts\aggregate_templates_for_qa.py,53.0,"LOGGER.info(""Code configuration set up; %d simulations will be performed"", settings.n_sim)",aggregate_templates_for_qa.py,Code
aggregate_templates_for_qa.py,\scripts\engine_scripts\aggregate_templates_for_qa.py,83.0,"    LOGGER.info(""%s parameter file will be used"", file_name_parameters)",agg_templates,Function
aggregate_templates_for_qa.py,\scripts\engine_scripts\aggregate_templates_for_qa.py,122.0,"    LOGGER.info(""Outputs saved"")",agg_templates,Function
aggregate_templates_for_qa.py,\scripts\engine_scripts\aggregate_templates_for_qa.py,135.0,"    pickle.dump(list_filepaths, open(""filepaths.p"", ""wb""))",aggregate_templates_for_qa.py,Code
aggregate_templates_for_qa.py,\scripts\engine_scripts\aggregate_templates_for_qa.py,153.0,"        print(f'""{filename}"" failed')",aggregate_templates_for_qa.py,Code
aggregate_templates_for_qa.py,\scripts\engine_scripts\aggregate_templates_for_qa.py,154.0,        print(filepath),aggregate_templates_for_qa.py,Code
aggregate_templates_for_qa.py,\scripts\engine_scripts\aggregate_templates_for_qa.py,155.0,        print(e),aggregate_templates_for_qa.py,Code
aggregate_templates_for_qa.py,\scripts\engine_scripts\aggregate_templates_for_qa.py,160.0,"        print(f'ignored ""{filename}"" as this is not approved or v13')",aggregate_templates_for_qa.py,Code
calculate_normalisation_params.py,\scripts\engine_scripts\calculate_normalisation_params.py,6.0,LOGGER = logging.getLogger(__name__),calculate_normalisation_params.py,Code
calculate_normalisation_params.py,\scripts\engine_scripts\calculate_normalisation_params.py,21.0,print(,calculate_normalisation_params.py,Code
calculate_normalisation_params.py,\scripts\engine_scripts\calculate_normalisation_params.py,25.0,print(,calculate_normalisation_params.py,Code
calculate_normalisation_params.py,\scripts\engine_scripts\calculate_normalisation_params.py,29.0,print(,calculate_normalisation_params.py,Code
calculate_normalisation_params.py,\scripts\engine_scripts\calculate_normalisation_params.py,32.0,print(,calculate_normalisation_params.py,Code
calculate_normalisation_params.py,\scripts\engine_scripts\calculate_normalisation_params.py,36.0,"print(""Quantitative PD cap (quant score max): "" + str(df.loc[0, ""cap""]))",calculate_normalisation_params.py,Code
calculate_normalisation_params.py,\scripts\engine_scripts\calculate_normalisation_params.py,37.0,"print(""Quantitative PD floor (quant score min): "" + str(df.loc[0, ""floor""]))",calculate_normalisation_params.py,Code
iteratively_remove_obs.py,\scripts\lgd_calibration\iteratively_remove_obs.py,65.0,"print(""Coefficient Variation Test 1 Current Portfolio:"")",iteratively_remove_obs.py,Code
iteratively_remove_obs.py,\scripts\lgd_calibration\iteratively_remove_obs.py,66.0,"print(round(coeff_variation(df_res['Current_Portfolio_LGD']), 3))",iteratively_remove_obs.py,Code
iteratively_remove_obs.py,\scripts\lgd_calibration\iteratively_remove_obs.py,68.0,"print(""Coefficient Variation Test 1 Default Portfolio:"")",iteratively_remove_obs.py,Code
iteratively_remove_obs.py,\scripts\lgd_calibration\iteratively_remove_obs.py,69.0,"print(round(coeff_variation(df_res['Default_Portfolio_LGD']), 3))",iteratively_remove_obs.py,Code
lgd_calibration_script.py,\scripts\lgd_calibration\lgd_calibration_script.py,104.0,    print(statsmodels.stats.stattools.durbin_watson(model.resid)),autocorrelation_of_residuals_test,Function
lgd_calibration_stability.py,\scripts\lgd_calibration\lgd_calibration_stability.py,60.0,    print(default_baseline_lgd_value),lgd_calibration_stability.py,Code
search_folder.py,\scripts\search_scripts\search_folder.py,26.0,"deals_without_msg.to_csv(settings.output_dir / ""deals_wihout_msg.csv"")",search_folder.py,Code
search_shared_drive.py,\scripts\search_scripts\search_shared_drive.py,32.0,"    df_found_items.to_csv(f""ContinuousDataCollectionSearch_{current_time_string}.csv"")",run_continuous_data_collection_search,Function
filename_search.py,\testing\filename_search.py,7.0,"print(""reading_filepaths"")",filename_search.py,Code
filename_search.py,\testing\filename_search.py,9.0,"pickle.dump(list_filepaths, open(settings.root_path / ""filepaths.p"", ""wb""))",filename_search.py,Code
filename_search.py,\testing\filename_search.py,22.0,"            print(f'""{filename}"" adheres to standards""')",filename_search.py,Code
filename_search.py,\testing\filename_search.py,29.0,"                print(f""{filename} added to misspelled files"")",filename_search.py,Code
filename_search.py,\testing\filename_search.py,32.0,"                print(f'ignored ""{filename}"" as this is not approved or v13')",filename_search.py,Code
filename_search.py,\testing\filename_search.py,39.0,"            print(f""{filename} added to misspelled files"")",filename_search.py,Code
filename_search.py,\testing\filename_search.py,42.0,"            print(f'ignored ""{filename}"" as this is not approved or v13')",filename_search.py,Code
filename_search.py,\testing\filename_search.py,44.0,"misspelled_filenames.to_csv(settings.root_path / ""misspelled_filenames.csv"")",filename_search.py,Code
filename_search.py,\testing\filename_search.py,45.0,"misspelled_filenames.to_csv(settings.root_path / ""misspelled_filenames-alternative.csv"", sep="";"")",filename_search.py,Code
test_utils.py,\testing\test_utils.py,74.0,"                    print(year, col)",DataFrameTestCase,Class
